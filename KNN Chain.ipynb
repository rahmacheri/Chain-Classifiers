{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.datasets import make_multilabel_classification\nfrom sklearn.metrics import classification_report, coverage_error, label_ranking_average_precision_score, hamming_loss\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import ClassifierChain\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom scipy.io import loadmat, savemat\nimport os\nimport time\n\ndef main_knn(scenario_name, snr_value, top_k=44):\n    # Load data\n    train_X = loadmat(f'/path/{scenario_name}-{snr_value}-train/data.mat')['datat']\n    train_Y = loadmat(f'/path/{scenario_name}-{snr_value}-train-labels/labels.mat')['Labels']\n    valid_X = loadmat(f'/path/{scenario_name}-{snr_value}-valid/data.mat')['datat']\n    valid_Y = loadmat(f'/path/{scenario_name}-{snr_value}-valid-labels/labels.mat')['Labels']\n    test_X = loadmat(f'/path/{scenario_name}-{snr_value}-test/data.mat')['datat']\n    test_Y = loadmat(f'/path/{scenario_name}-{snr_value}-test-labels/labels.mat')['Labels']\n    \n    # Reshape data\n    train_X = np.transpose(train_X, (3, 0, 1, 2)).reshape(6000, -1)\n    valid_X = np.transpose(valid_X, (3, 0, 1, 2)).reshape(2000, -1)\n    test_X = np.transpose(test_X, (3, 0, 1, 2)).reshape(2000, -1)\n\n    # Concatenate train and validation data\n    train_X = np.concatenate((train_X, valid_X))\n    train_Y = np.concatenate((train_Y, valid_Y))\n\n    # Standardize the data\n    scaler = StandardScaler()\n    train_X = scaler.fit_transform(train_X)\n    test_X = scaler.transform(test_X)\n\n    # Reduce dimensionality with PCA\n    pca = PCA(n_components=10)\n    train_X = pca.fit_transform(train_X)\n    test_X = pca.transform(test_X)\n\n    # Perform grid search to find the best k for KNeighborsClassifier\n    \n    param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n    knn = KNeighborsClassifier()\n    grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=3, scoring='accuracy')\n    grid_search.fit(train_X, train_Y)\n\n    print(f\"Best parameters found: {grid_search.best_params_}\")\n    best_knn = grid_search.best_estimator_\n\n    # Initialize CalibratedClassifierCV with 'sigmoid' calibration using the best KNeighborsClassifier\n    calibrated_knn = CalibratedClassifierCV(best_knn, method='sigmoid')\n\n    # Initialize ClassifierChain with CalibratedClassifierCV\n    chain_classifier_knn = ClassifierChain(calibrated_knn, order='random', random_state=42)\n\n    # Fit the data to the ClassifierChain with the calibrated KNeighborsClassifier\n    chain_classifier_knn.fit(train_X, train_Y)\n\n    start_inference_time = time.time()\n\n    # Predict probabilities for the test set using the chain classifier\n    y_pred_prob_knn = chain_classifier_knn.predict_proba(test_X)\n    sorted_indices_knn = np.argsort(-y_pred_prob_knn, axis=1)\n\n    # Initialize array to store top k labels for each sample\n    y_pred_chain_knn = np.zeros_like(test_Y)\n    \n    # Select top k labels for each sample\n    for i in range(len(test_Y)):\n        top_indices = sorted_indices_knn[i, :top_k]\n        y_pred_chain_knn[i, top_indices] = 1\n\n    end_inference_time = time.time()\n    inference_time = end_inference_time - start_inference_time\n    # Print the inference time\n    print(f\"Inference Time: {inference_time} seconds\", flush=True)\n\n    # Compute classification metrics\n    report_knn = classification_report(test_Y, y_pred_chain_knn)\n    coverage_err_knn = coverage_error(test_Y, y_pred_prob_knn)\n    avg_precision_knn = label_ranking_average_precision_score(test_Y, y_pred_prob_knn)\n    hamming_knn = hamming_loss(test_Y, y_pred_chain_knn)\n\n    print(\"Classification Report (KNeighborsClassifier and CalibratedClassifierCV):\\n\", report_knn)\n    print(f\"Coverage Error (KNeighborsClassifier and CalibratedClassifierCV): {coverage_err_knn:.4f}\")\n    print(f\"Label Ranking Average Precision Score (KNeighborsClassifier and CalibratedClassifierCV): {avg_precision_knn:.4f}\")\n    print(f\"Hamming Loss (KNeighborsClassifier and CalibratedClassifierCV): {hamming_knn:.4f}\")\n\n    # Save predictions\n    directory_knn = \"/your-path/\"\n    os.makedirs(directory_knn, exist_ok=True)\n    filename_knn = f\"{scenario_name}_{snr_value}_KNN_Chain_Calibrated.mat\"\n    filepath_knn = os.path.join(directory_knn, filename_knn)\n\n    try:\n        savemat(filepath_knn, {\"y_pred_chain_knn\": y_pred_chain_knn})\n    except Exception as e:\n        print(\"Error saving file (KNeighborsClassifier and CalibratedClassifierCV):\", e)\n\n# Example usage:\nif __name__ == \"__main__\":\n    scenario_name = \"44\"\n    snr_value = 'snr10'\n    main_knn(scenario_name, snr_value)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}